from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_community.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
import os

# ðŸ” Din OpenAI API-nÃ¸gle
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY") or "DIN-OPENAI-API-NÃ˜GLE-HER"

# ðŸ§  IndlÃ¦s embeddings og vectorstore
embedding_model = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)
vectorstore = FAISS.load_local("vectorstore", embedding_model, allow_dangerous_deserialization=True)
#retriever = vectorstore.as_retriever(search_kwargs={"k": 16})
retriever = vectorstore.as_retriever(search_type="mmr", search_kwargs={"k": 16, "lambda_mult": 0.25})


# ðŸ“‹ Prompt template til kontrol
template = """
Du er en faktuel, regelbaseret assistent for JYSK. Brug udelukkende konteksten nedenfor til at besvare spÃ¸rgsmÃ¥let.
Svar kort og prÃ¦cist. Hvis svaret ikke findes i konteksten, skal du svare: "Det fremgÃ¥r ikke af dokumenterne."

Kontekst:
{context}

SpÃ¸rgsmÃ¥l:
{question}
"""

QA_PROMPT = PromptTemplate(
    template=template,
    input_variables=["context", "question"]
)

# ðŸ’¬ Sprogmodel
llm = ChatOpenAI(temperature=0, model="gpt-4", openai_api_key=OPENAI_API_KEY)

# ðŸ”„ Retrieval + promptstyret QA-kÃ¦de
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type="stuff",
    retriever=retriever,
    chain_type_kwargs={"prompt": QA_PROMPT},
    return_source_documents=True
)

# ðŸ–¥ï¸ Terminalchat
def chat():
    print("RAG-chat (med promptkontrol) klar. Skriv 'exit' for at afslutte.\n")
    while True:
        query = input("> ")
        if query.lower() in ["exit", "quit"]:
            break

        result = qa_chain(query)
        print("\nSvar:\n")
        print(result["result"])

        print("\nKilder:")
        for doc in result["source_documents"]:
            meta = doc.metadata
            print(f"- {meta.get('source', '?')} (side {meta.get('page', '?')}, type: {meta.get('type', '')})")
        print()

if __name__ == "__main__":
    chat()
